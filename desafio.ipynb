{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:01.000]  Cresciani?\n",
      "[00:01.000 --> 00:02.000]  Oi Cresciani, boa tarde, tudo bem?\n",
      "[00:02.000 --> 00:03.000]  Oi, tudo certo?\n",
      "[00:03.000 --> 00:04.000]  Que bom.\n",
      "[00:04.000 --> 00:07.000]  Eu gostaria de falar com a Luana da exportação, seria possível?\n",
      "[00:07.000 --> 00:17.000]  Sim, deixa eu só ver qual é o ramal dela, só uma lindinha, tá?\n",
      "[00:17.000 --> 00:24.000]  Obrigada.\n",
      "[00:48.000 --> 00:51.000]  Oi Luana, boa tarde, tudo bem?\n",
      "[00:51.000 --> 00:53.000]  Oi, tudo bem, e você?\n",
      "[00:53.000 --> 00:54.000]  Bem, também.\n",
      "[00:54.000 --> 00:57.000]  Luana, me chamo Jacquelin, fala que dá re-alogue.\n",
      "[00:57.000 --> 01:06.000]  Há um tempinho atrás, uns dias atrás, a gente havia conversado em relação a uma apresentação prévia da nossa empresa pra você, você se recorda?\n",
      "[01:06.000 --> 01:08.000]  Sim, lembro assim.\n",
      "[01:08.000 --> 01:15.000]  A gente até tinha chego a agendar uma reunião pro dia 10, mas por algum equivo que acabou não ocorrendo, né?\n",
      "[01:15.000 --> 01:28.000]  Então, o motivo da milização neste momento é verificar com você uma nova oportunidade de a gente poder estar deixando o pré-agendar pra você conhecer um pouco mais sobre como a re-alogue funciona?\n",
      "[01:28.000 --> 01:30.000]  O que que você me disse?\n",
      "[01:31.000 --> 01:50.000]  No momento agora, a gente tá bem apertado, sabe? A gente tá sem uma pessoa, nossa acordadora também tá saindo, daí a gente é bem difícil de fechar um tempo, tanto que eu tinha marcado ali a reunião, porque a gente tava mais tranquilo, mas acabamos tendo visitas aqui na Poisson e ficou meio em cima, assim, sabe?\n",
      "[01:50.000 --> 01:53.000]  Sim, sim, não, entendo perfeitamente.\n",
      "[01:53.000 --> 02:11.000]  Luana, o que a gente pode estar fazendo é também agendando mais pro final do dia, assim, não fica tão incômodo, digamos, durante o dia, né? Por conta das suas demandas, a gente pode estar agendando ali pra 17 horas, 17h30, fica bom pra você?\n",
      "[02:11.000 --> 02:25.000]  Pode ser, mas vocês conseguem fazer pra semana que vem, que daí a minha colega já vai tá voltando de férias, daí a gente vai conseguir dar uma organizada no studio ou na última semana do mês também pra mim, isso seria até melhor.\n",
      "[02:25.000 --> 02:32.000]  Sim, sim, conseguimos sim. Eu tenho aqui disponível pro dia 23, na quarta-feira que vem. Pode ser?\n",
      "[02:32.000 --> 02:33.000]  Pode ser, ja.\n",
      "[02:33.000 --> 02:39.000]  Tá, então eu vou deixar aqui a agendadinha no dia 23 às 17h30 ou às 17h00, que é bom pra você?\n",
      "[02:39.000 --> 02:42.000]  Pode ser, acho que às 17h00 é o melhor.\n",
      "[02:42.000 --> 02:50.000]  Perfeito, então, vou deixar a agendadinha e após a nossa ligação eu vou estar te mandando um e-mail com o link da reunião, tá bom, ou não?\n",
      "[02:50.000 --> 02:57.000]  Só me tira uma dúvida, por gentileza. Você utiliza o Meet ou você utiliza o Teams?\n",
      "[02:57.000 --> 03:01.000]  O Teams. O Meet acho que eu não tenho aqui, só tenho Zoom.\n",
      "[03:01.000 --> 03:03.000]  Ah, perfeito, então.\n",
      "[03:03.000 --> 03:08.000]  Só pra eu informar o meu comercial pra poder gerar o link 7, tá bom?\n",
      "[03:08.000 --> 03:12.000]  Muito obrigada pela oportunidade, nos vemos em breve.\n",
      "[03:12.000 --> 03:13.000]  Obrigada, igualmente.\n",
      "[03:13.000 --> 03:15.000]  Obrigada, tchau, tchau.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"small\")\n",
    "def convert_to_text(audio_path):\n",
    "    result = model.transcribe(audio_path, language=\"pt\", fp16=False, verbose=True)\n",
    "    message_ctn=result[\"text\"]\n",
    "    return result\n",
    "\n",
    "content = convert_to_text(\"audio/agendamento_de_reuniao.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9807e9e86e4d278a222df08952d121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069cd43827e248209f8d845a06d586b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1d1a3a170b494ca14c67ce0f8f8001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bcea9a37864f49aefa25b9879fa67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a8ffb9dc4a499fb5d8f80f737778eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Specify the model and tokenizer for Portuguese sentiment analysis\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create the sentiment analysis pipeline with the specified model and tokenizer\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e5dbd890eb44ee89a428697f52d71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868f1d2ff00846ac8117191ac820c8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ff6ac743ef4e35bd29f121c696a021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/438k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e4a0cc46f84c0ebbb4dfec5816e64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2149d77d3de343fbb1334fc423b6ce64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78244c7d13924378b94840ec289ce796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7304731607437134},\n",
       " {'label': 'POSITIVE', 'score': 0.5405580997467041}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    BertForSequenceClassification,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "finbert_pt_br_tokenizer = AutoTokenizer.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "finbert_pt_br_model = BertForSequenceClassification.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "\n",
    "finbert_pt_br_pipeline = pipeline(task='text-classification', model=finbert_pt_br_model, tokenizer=finbert_pt_br_tokenizer)\n",
    "finbert_pt_br_pipeline(['Hoje a bolsa caiu', 'Hoje a bolsa subiu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEUTRAL', 'score': 0.5232409834861755}, {'label': 'NEUTRAL', 'score': 0.6070596575737}, {'label': 'NEUTRAL', 'score': 0.5676959753036499}, {'label': 'NEUTRAL', 'score': 0.46651458740234375}, {'label': 'NEUTRAL', 'score': 0.6692174673080444}, {'label': 'NEUTRAL', 'score': 0.6604355573654175}, {'label': 'NEUTRAL', 'score': 0.4864816963672638}, {'label': 'NEUTRAL', 'score': 0.6104426980018616}, {'label': 'NEUTRAL', 'score': 0.5572894215583801}, {'label': 'NEUTRAL', 'score': 0.48721784353256226}, {'label': 'NEUTRAL', 'score': 0.636584997177124}, {'label': 'NEUTRAL', 'score': 0.6640109419822693}, {'label': 'NEUTRAL', 'score': 0.5087591409683228}, {'label': 'NEUTRAL', 'score': 0.5839784145355225}, {'label': 'NEUTRAL', 'score': 0.7002053260803223}, {'label': 'NEUTRAL', 'score': 0.546238362789154}, {'label': 'NEGATIVE', 'score': 0.6925179362297058}, {'label': 'NEUTRAL', 'score': 0.5140314698219299}, {'label': 'NEUTRAL', 'score': 0.6568262577056885}, {'label': 'NEUTRAL', 'score': 0.707248330116272}, {'label': 'NEUTRAL', 'score': 0.6666975021362305}, {'label': 'NEUTRAL', 'score': 0.5144811272621155}, {'label': 'NEUTRAL', 'score': 0.6728055477142334}, {'label': 'NEUTRAL', 'score': 0.6114063262939453}, {'label': 'NEUTRAL', 'score': 0.7244874238967896}, {'label': 'NEUTRAL', 'score': 0.632779598236084}, {'label': 'NEUTRAL', 'score': 0.6143664121627808}, {'label': 'NEUTRAL', 'score': 0.47417300939559937}, {'label': 'NEUTRAL', 'score': 0.648720920085907}, {'label': 'NEUTRAL', 'score': 0.5669218897819519}, {'label': 'NEUTRAL', 'score': 0.5020720958709717}, {'label': 'NEUTRAL', 'score': 0.4833076298236847}]\n"
     ]
    }
   ],
   "source": [
    "data = [\"I love you\", \"I hate you\"]\n",
    "data = [segment['text'] for segment in content['segments']]\n",
    "pipeline = finbert_pt_br_pipeline(data)\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEUTRAL  -   Cresciani?\n",
      "NEUTRAL  -   Oi Cresciani, boa tarde, tudo bem?\n",
      "NEUTRAL  -   Oi, tudo certo?\n",
      "NEUTRAL  -   Que bom.\n",
      "NEUTRAL  -   Eu gostaria de falar com a Luana da exportação, seria possível?\n",
      "NEUTRAL  -   Sim, deixa eu só ver qual é o ramal dela, só uma lindinha, tá?\n",
      "NEUTRAL  -   Obrigada.\n",
      "NEUTRAL  -   Oi Luana, boa tarde, tudo bem?\n",
      "NEUTRAL  -   Oi, tudo bem, e você?\n",
      "NEUTRAL  -   Bem, também.\n",
      "NEUTRAL  -   Luana, me chamo Jacquelin, fala que dá re-alogue.\n",
      "NEUTRAL  -   Há um tempinho atrás, uns dias atrás, a gente havia conversado em relação a uma apresentação prévia da nossa empresa pra você, você se recorda?\n",
      "NEUTRAL  -   Sim, lembro assim.\n",
      "NEUTRAL  -   A gente até tinha chego a agendar uma reunião pro dia 10, mas por algum equivo que acabou não ocorrendo, né?\n",
      "NEUTRAL  -   Então, o motivo da milização neste momento é verificar com você uma nova oportunidade de a gente poder estar deixando o pré-agendar pra você conhecer um pouco mais sobre como a re-alogue funciona?\n",
      "NEUTRAL  -   O que que você me disse?\n",
      "NEGATIVE  -   No momento agora, a gente tá bem apertado, sabe? A gente tá sem uma pessoa, nossa acordadora também tá saindo, daí a gente é bem difícil de fechar um tempo, tanto que eu tinha marcado ali a reunião, porque a gente tava mais tranquilo, mas acabamos tendo visitas aqui na Poisson e ficou meio em cima, assim, sabe?\n",
      "NEUTRAL  -   Sim, sim, não, entendo perfeitamente.\n",
      "NEUTRAL  -   Luana, o que a gente pode estar fazendo é também agendando mais pro final do dia, assim, não fica tão incômodo, digamos, durante o dia, né? Por conta das suas demandas, a gente pode estar agendando ali pra 17 horas, 17h30, fica bom pra você?\n",
      "NEUTRAL  -   Pode ser, mas vocês conseguem fazer pra semana que vem, que daí a minha colega já vai tá voltando de férias, daí a gente vai conseguir dar uma organizada no studio ou na última semana do mês também pra mim, isso seria até melhor.\n",
      "NEUTRAL  -   Sim, sim, conseguimos sim. Eu tenho aqui disponível pro dia 23, na quarta-feira que vem. Pode ser?\n",
      "NEUTRAL  -   Pode ser, ja.\n",
      "NEUTRAL  -   Tá, então eu vou deixar aqui a agendadinha no dia 23 às 17h30 ou às 17h00, que é bom pra você?\n",
      "NEUTRAL  -   Pode ser, acho que às 17h00 é o melhor.\n",
      "NEUTRAL  -   Perfeito, então, vou deixar a agendadinha e após a nossa ligação eu vou estar te mandando um e-mail com o link da reunião, tá bom, ou não?\n",
      "NEUTRAL  -   Só me tira uma dúvida, por gentileza. Você utiliza o Meet ou você utiliza o Teams?\n",
      "NEUTRAL  -   O Teams. O Meet acho que eu não tenho aqui, só tenho Zoom.\n",
      "NEUTRAL  -   Ah, perfeito, então.\n",
      "NEUTRAL  -   Só pra eu informar o meu comercial pra poder gerar o link 7, tá bom?\n",
      "NEUTRAL  -   Muito obrigada pela oportunidade, nos vemos em breve.\n",
      "NEUTRAL  -   Obrigada, igualmente.\n",
      "NEUTRAL  -   Obrigada, tchau, tchau.\n"
     ]
    }
   ],
   "source": [
    "for text,result in zip(data, pipeline):\n",
    "    print(result['label'], \" - \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lig. Negativo  -   Cresciani?\n",
      "Positivo  -   Oi Cresciani, boa tarde, tudo bem?\n",
      "Negativo  -   Oi, tudo certo?\n",
      "Positivo  -   Que bom.\n",
      "Negativo  -   Eu gostaria de falar com a Luana da exportação, seria possível?\n",
      "Lig. Negativo  -   Sim, deixa eu só ver qual é o ramal dela, só uma lindinha, tá?\n",
      "Positivo  -   Obrigada.\n",
      "Neutro  -   Oi Luana, boa tarde, tudo bem?\n",
      "Positivo  -   Oi, tudo bem, e você?\n",
      "Lig. Positivo  -   Bem, também.\n",
      "Negativo  -   Luana, me chamo Jacquelin, fala que dá re-alogue.\n",
      "Negativo  -   Há um tempinho atrás, uns dias atrás, a gente havia conversado em relação a uma apresentação prévia da nossa empresa pra você, você se recorda?\n",
      "Neutro  -   Sim, lembro assim.\n",
      "Negativo  -   A gente até tinha chego a agendar uma reunião pro dia 10, mas por algum equivo que acabou não ocorrendo, né?\n",
      "Neutro  -   Então, o motivo da milização neste momento é verificar com você uma nova oportunidade de a gente poder estar deixando o pré-agendar pra você conhecer um pouco mais sobre como a re-alogue funciona?\n",
      "Negativo  -   O que que você me disse?\n",
      "Lig. Negativo  -   No momento agora, a gente tá bem apertado, sabe? A gente tá sem uma pessoa, nossa acordadora também tá saindo, daí a gente é bem difícil de fechar um tempo, tanto que eu tinha marcado ali a reunião, porque a gente tava mais tranquilo, mas acabamos tendo visitas aqui na Poisson e ficou meio em cima, assim, sabe?\n",
      "Negativo  -   Sim, sim, não, entendo perfeitamente.\n",
      "Neutro  -   Luana, o que a gente pode estar fazendo é também agendando mais pro final do dia, assim, não fica tão incômodo, digamos, durante o dia, né? Por conta das suas demandas, a gente pode estar agendando ali pra 17 horas, 17h30, fica bom pra você?\n",
      "Neutro  -   Pode ser, mas vocês conseguem fazer pra semana que vem, que daí a minha colega já vai tá voltando de férias, daí a gente vai conseguir dar uma organizada no studio ou na última semana do mês também pra mim, isso seria até melhor.\n",
      "Negativo  -   Sim, sim, conseguimos sim. Eu tenho aqui disponível pro dia 23, na quarta-feira que vem. Pode ser?\n",
      "Neutro  -   Pode ser, ja.\n",
      "Negativo  -   Tá, então eu vou deixar aqui a agendadinha no dia 23 às 17h30 ou às 17h00, que é bom pra você?\n",
      "Neutro  -   Pode ser, acho que às 17h00 é o melhor.\n",
      "Positivo  -   Perfeito, então, vou deixar a agendadinha e após a nossa ligação eu vou estar te mandando um e-mail com o link da reunião, tá bom, ou não?\n",
      "Lig. Negativo  -   Só me tira uma dúvida, por gentileza. Você utiliza o Meet ou você utiliza o Teams?\n",
      "Neutro  -   O Teams. O Meet acho que eu não tenho aqui, só tenho Zoom.\n",
      "Positivo  -   Ah, perfeito, então.\n",
      "Negativo  -   Só pra eu informar o meu comercial pra poder gerar o link 7, tá bom?\n",
      "Positivo  -   Muito obrigada pela oportunidade, nos vemos em breve.\n",
      "Positivo  -   Obrigada, igualmente.\n",
      "Positivo  -   Obrigada, tchau, tchau.\n"
     ]
    }
   ],
   "source": [
    "feelings = {\"1 star\":\"Negativo\", \"2 stars\":\"Lig. Negativo\", \"3 stars\":\"Neutro\", \"4 stars\":\"Lig. Positivo\", \"5 stars\":\"Positivo\"}\n",
    "for sentiment, segment in zip(pipeline, data):\n",
    "    print(feelings[sentiment['label']],\" - \" , segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.weight', 'projector.bias', 'classifier.bias', 'wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 18257616432 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[0;32m     43\u001b[0m audio_path_mp3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio/agendamento_de_reuniao.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 44\u001b[0m sentiment_class \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path_mp3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Imprimindo o resultado\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasse de Sentimento Predita:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sentiment_class)\n",
      "Cell \u001b[1;32mIn[28], line 34\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Fazendo a predição\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 34\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Obtendo as previsões\u001b[39;00m\n\u001b[0;32m     37\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:2095\u001b[0m, in \u001b[0;36mWav2Vec2ForSequenceClassification.forward\u001b[1;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[0;32m   2092\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   2093\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_weighted_layer_sum \u001b[38;5;28;01melse\u001b[39;00m output_hidden_states\n\u001b[1;32m-> 2095\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwav2vec2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2096\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2098\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2099\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_weighted_layer_sum:\n\u001b[0;32m   2104\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[_HIDDEN_STATES_START_POSITION]\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1561\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[1;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1556\u001b[0m hidden_states, extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_projection(extract_features)\n\u001b[0;32m   1557\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_hidden_states(\n\u001b[0;32m   1558\u001b[0m     hidden_states, mask_time_indices\u001b[38;5;241m=\u001b[39mmask_time_indices, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\n\u001b[0;32m   1559\u001b[0m )\n\u001b[1;32m-> 1561\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1569\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:810\u001b[0m, in \u001b[0;36mWav2Vec2Encoder.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    803\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    804\u001b[0m             layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    805\u001b[0m             hidden_states,\n\u001b[0;32m    806\u001b[0m             attention_mask,\n\u001b[0;32m    807\u001b[0m             output_attentions,\n\u001b[0;32m    808\u001b[0m         )\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:689\u001b[0m, in \u001b[0;36mWav2Vec2EncoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    688\u001b[0m     attn_residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 689\u001b[0m     hidden_states, attn_weights, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    693\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m attn_residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:590\u001b[0m, in \u001b[0;36mWav2Vec2Attention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    587\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mproj_shape)\n\u001b[0;32m    589\u001b[0m src_len \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 590\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_weights\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, src_len):\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    594\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention weights should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39msrc_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_weights\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 18257616432 bytes."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "\n",
    "# Carregando o modelo e o processador\n",
    "model_name = \"facebook/wav2vec2-base-960h\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Função para carregar e processar áudio MP3\n",
    "def process_audio_mp3(audio_path):\n",
    "    audio = AudioSegment.from_mp3(audio_path)\n",
    "\n",
    "    # Configurando a taxa de amostragem para 16000 Hz\n",
    "    target_sampling_rate = 16000\n",
    "    if audio.frame_rate != target_sampling_rate:\n",
    "        audio = audio.set_frame_rate(target_sampling_rate)\n",
    "\n",
    "    audio_bytes = BytesIO()\n",
    "    audio.export(audio_bytes, format=\"wav\")\n",
    "    audio_array = torch.tensor(AudioSegment.from_wav(audio_bytes).get_array_of_samples()).float()\n",
    "    return audio_array, target_sampling_rate\n",
    "\n",
    "# Função para realizar a análise de sentimento\n",
    "def analyze_sentiment(audio_path):\n",
    "    audio_array, frame_rate = process_audio_mp3(audio_path)\n",
    "\n",
    "    # Tokenizando e formatando os dados\n",
    "    inputs = processor(audio_array.numpy(), return_tensors=\"pt\", sampling_rate=frame_rate)\n",
    "\n",
    "    # Fazendo a predição\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Obtendo as previsões\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Exemplo de uso\n",
    "audio_path_mp3 = \"audio/agendamento_de_reuniao.mp3\"\n",
    "sentiment_class = analyze_sentiment(audio_path_mp3)\n",
    "\n",
    "# Imprimindo o resultado\n",
    "print(\"Classe de Sentimento Predita:\", sentiment_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "example = content['segments']\n",
    "json_object = json.dumps(example, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"json/transcrição.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_example = {\"id\":\"123\", \"messages\":[]}\n",
    "for segment in content['segments']:\n",
    "    conversation_example['messages'].append({\"author\":segment['id'], \"text\":segment['text']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ASAP' from 'asap' (c:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\asap\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01masap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASAP \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_conversation\u001b[39m(conversation_json):\n\u001b[0;32m      6\u001b[0m     sentiment_analyzer \u001b[38;5;241m=\u001b[39m ASAP()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ASAP' from 'asap' (c:\\Users\\lucas\\anaconda3\\envs\\Hapvida\\lib\\site-packages\\asap\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from asap import ASAP \n",
    "\n",
    "def analyze_conversation(conversation_json):\n",
    "\n",
    "    sentiment_analyzer = ASAP()\n",
    "    \n",
    "    conversation = json.loads(conversation_json)\n",
    "    messages = conversation['messages']\n",
    "    \n",
    "    results = []\n",
    "    for message in messages:\n",
    "        text = message['text']\n",
    "        \n",
    "        sentiment = sentiment_analyzer.analyze(text) \n",
    "        label = \"neutral\"\n",
    "        if sentiment >= 0.2:\n",
    "            label = \"positive\"\n",
    "        elif sentiment <= -0.2:\n",
    "            label = \"negative\"\n",
    "            \n",
    "        message_result = {\n",
    "            \"text\": text, \n",
    "            \"sentiment\": {\n",
    "                \"label\": label,\n",
    "                \"score\": sentiment\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        results.append(message_result)\n",
    "        \n",
    "    return json.dumps({\n",
    "        \"conversation_id\": conversation[\"id\"],\n",
    "        \"messages\": results \n",
    "    })\n",
    "\n",
    "conversation_example = \"\"\" \n",
    "{\n",
    "  \"id\": \"123\",\n",
    "  \"messages\": [\n",
    "      {\"author\": \"Maria\", \"text\": \"Bom dia!\"}, \n",
    "      {\"author\": \"João\", \"text\": \"Oi Maria, como você está hoje?\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asap\n",
    "dir(asap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hapvida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
